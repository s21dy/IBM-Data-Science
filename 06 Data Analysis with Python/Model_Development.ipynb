{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6198fcf1",
   "metadata": {},
   "source": [
    "# Key Statistical Concepts\n",
    "\n",
    "## Coefficient\n",
    "### Definition\n",
    "- A coefficient in regression analysis represents the change in the dependent variable for a one-unit change in the independent variable, holding all other variables constant.\n",
    "- It indicates the strength and direction of the relationship between an independent variable and the dependent variable.\n",
    "\n",
    "### Interpretation\n",
    "- Positive coefficient: Indicates a direct relationship between the independent variable and the dependent variable.\n",
    "- Negative coefficient: Indicates an inverse relationship between the independent variable and the dependent variable.\n",
    "- Magnitude: Indicates the size of the effect the independent variable has on the dependent variable.\n",
    "\n",
    "```python\n",
    "import statsmodels.api as sm\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    "coefficients = model.params\n",
    "print(coefficients)\n",
    "\n",
    "```\n",
    "[ Y = B0 + B1*X + B2*X2 ... BN*XN + E\\]\n",
    "- B = Coeffieience\n",
    "- E = Error Term\n",
    "\n",
    "## P-value\n",
    "### Definition\n",
    "- P-value is the probability of obtaining test results at least as extreme as the observed results, assuming that the null hypothesis is true.\n",
    "- It helps determine the statistical significance of the results.\n",
    "\n",
    "### Interpretation\n",
    "- Low p-value (< 0.05): Strong evidence against the null hypothesis, so you reject the null hypothesis.\n",
    "- High p-value (> 0.05): Weak evidence against the null hypothesis, so you fail to reject the null hypothesis.\n",
    "- Exactly 0.05: The threshold level of significance.\n",
    "\n",
    "```python\n",
    "import statsmodels.api as sm\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(Y, X).fit()\n",
    "p_values = model.pvalues\n",
    "print(p_values)\n",
    "```\n",
    "\n",
    "## R² Value (Coefficient of Determination)\n",
    "\n",
    "### Definition\n",
    "- **R² (R-squared)** is a statistical measure that represents the proportion of the variance in the dependent variable that is predictable from the independent variable(s).\n",
    "- It ranges from 0 to 1.\n",
    "\n",
    "### Interpretation\n",
    "- **0**: The independent variables do not explain any of the variability in the dependent variable.\n",
    "- **1**: The independent variables explain all of the variability in the dependent variable.\n",
    "- **Closer to 1**: Indicates a better fit of the model to the data.\n",
    "- **Closer to 0**: Indicates a poor fit of the model to the data.\n",
    "\n",
    "### Formula\n",
    "[ R^2 = 1 - \\frac{SS_{res}}{SS_{tot}} \\]\n",
    "- \\( SS_{res} \\): Sum of squares of residuals (unexplained variation).\n",
    "- \\( SS_{tot} \\): Total sum of squares (total variation in the data).\n",
    "\n",
    "### Example\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "X = df[['highway-mpg']]\n",
    "Y = df['price']\n",
    "lm.fit(X, Y)\n",
    "R_squared = lm.score(X, Y)\n",
    "print(R_squared)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23270420",
   "metadata": {},
   "source": [
    "# Model Development Pipeline\n",
    "\n",
    "## 1. Data Collection\n",
    "- Gather data from various sources (databases, APIs, CSV files, etc.).\n",
    "\n",
    "## 2. Data Preprocessing\n",
    "- **Load Data**: Import data into your analysis environment (e.g., pandas DataFrame in Python).\n",
    "- **Clean Data**: Handle missing values, remove duplicates, and correct data types.\n",
    "- **Feature Engineering**: Create new features, normalize/standardize data, and encode categorical variables.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Clean data\n",
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Feature engineering\n",
    "df['new_feature'] = df['existing_feature'] ** 2\n",
    "df = pd.get_dummies(df, columns=['categorical_feature'])\n",
    "\n",
    "``` \n",
    "### 3. Exploratory Data Analysis (EDA)\n",
    "- Descriptive Statistics: Summarize data using mean, median, mode, etc.\n",
    "- Visualizations: Create plots (scatter plots, histograms, box plots) to understand data distribution and relationships.\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Descriptive statistics\n",
    "print(df.describe())\n",
    "\n",
    "# Visualizations\n",
    "sns.pairplot(df)\n",
    "plt.show()\n",
    "\n",
    "```\n",
    "\n",
    "### 4. Feature Selection\n",
    "- Identify and select important features using correlation analysis, variance threshold, or more advanced techniques like Recursive Feature Elimination (RFE).\n",
    "\n",
    "```python\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Feature selection using RFE\n",
    "model = LinearRegression()\n",
    "rfe = RFE(model, n_features_to_select=5)\n",
    "fit = rfe.fit(X, Y)\n",
    "selected_features = X.columns[fit.support_]\n",
    "\n",
    "```\n",
    "### 5. Model Development\n",
    "- Split Data: Divide data into training and testing sets.\n",
    "- Train Model: Fit the model to the training data.\n",
    "- Evaluate Model: Use R² value, p-values, and coefficients to evaluate the model.\n",
    "\n",
    "```python\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Split data\n",
    "X = df[selected_features]\n",
    "Y = df['target']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate model\n",
    "R_squared = model.score(X_test, Y_test)\n",
    "print(f\"R² value: {R_squared}\")\n",
    "\n",
    "# Using statsmodels for p-values and coefficients\n",
    "X_train_sm = sm.add_constant(X_train)\n",
    "sm_model = sm.OLS(Y_train, X_train_sm).fit()\n",
    "print(sm_model.summary())\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "### 6. Model Evaluation\n",
    "\n",
    "- Residual Analysis: Check residual plots for homoscedasticity and patterns.\n",
    "- Performance Metrics: Calculate metrics like RMSE, MAE, and adjusted R².\n",
    "- Validation: Perform cross-validation to assess model generalization.\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Residual analysis\n",
    "residuals = Y_test - model.predict(X_test)\n",
    "sns.residplot(x=Y_test, y=residuals, lowess=True)\n",
    "plt.xlabel('Fitted values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.show()\n",
    "\n",
    "# Performance metrics\n",
    "Y_pred = model.predict(X_test)\n",
    "rmse = mean_squared_error(Y_test, Y_pred, squared=False)\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "adjusted_R_squared = 1 - (1-R_squared)*(len(Y_test)-1)/(len(Y_test)-X_test.shape[1]-1)\n",
    "print(f\"RMSE: {rmse}, MAE: {mae}, Adjusted R²: {adjusted_R_squared}\")\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(model, X, Y, cv=5, scoring='r2')\n",
    "print(f\"Cross-validated R²: {cv_scores.mean()}\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09838a74",
   "metadata": {},
   "source": [
    "# Fast Summary\n",
    "\n",
    "## R² Value\n",
    "- What it is: The R² value tells us how well our model explains the variation in the data. It ranges from 0 to 1.\n",
    "- If the R² value is close to 1, it means our model is very good at predicting the target variable (price). If it’s close to 0, it means the model isn’t very good at making predictions.\n",
    "- Example: If we get an R² value of 0.8, it means 80% of the variability in car prices can be explained by the model using highway-mpg.\n",
    "\n",
    "## p-value\n",
    "- What it is: The p-value helps us determine if the results we see are statistically significant.\n",
    "- In simple terms: A small p-value (typically less than 0.05) means that the feature (e.g., highway-mpg) has a significant impact on the target variable (price). If the p-value is large, it means the feature might not be important.\n",
    "- Example: If the p-value for highway-mpg is 0.01, it means that highway-mpg is **likely a significant factor** in determining car prices.\n",
    "\n",
    "## Coefficients\n",
    "- What it is: Coefficients tell us how much the **target variable** (price) changes when the feature (e.g., highway-mpg) changes by one unit.\n",
    "- In simple terms: If the coefficient is positive, it means that as the feature increases, the target variable also increases. If it’s negative, the target variable decreases.\n",
    "- Example: If the coefficient for highway-mpg is -1000, it means that for each additional mile per gallon on the highway, the price of the car decreases by 1000.\n",
    "\n",
    "## Mean Squared Error (MSE)\n",
    "- What it is: MSE measures the average squared difference between the actual prices and the prices predicted by the model.\n",
    "- In simple terms: A smaller MSE means our predictions are closer to the actual prices, indicating a better model.\n",
    "- Example: If the MSE is 1500, it means that, on average, the difference between the actual car prices and the predicted prices is $1500 squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237f843c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
